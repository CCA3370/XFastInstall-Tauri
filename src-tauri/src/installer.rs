use anyhow::{Context, Result};
use glob::Pattern;
use std::fs;
use std::path::{Component, Path, PathBuf};
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::{Arc, Mutex};
use std::time::Instant;
use tauri::{AppHandle, Emitter};

use crate::logger;
use crate::logger::{tr, LogMsg};
use crate::models::{AddonType, InstallPhase, InstallProgress, InstallResult, InstallTask, TaskResult};

/// Maximum allowed extraction size (20 GB) - archives larger than this will show a warning
pub const MAX_EXTRACTION_SIZE: u64 = 20 * 1024 * 1024 * 1024;

/// Maximum compression ratio to detect zip bombs (100:1)
pub const MAX_COMPRESSION_RATIO: u64 = 100;

/// Check if a filename matches any of the given glob patterns
fn matches_any_pattern(filename: &str, patterns: &[String]) -> bool {
    patterns.iter().any(|pattern| {
        Pattern::new(pattern)
            .map(|p| p.matches(filename))
            .unwrap_or(false)
    })
}

/// Sanitize a file path to prevent path traversal attacks
/// Returns None if the path is unsafe (contains `..` or is absolute)
pub fn sanitize_path(path: &Path) -> Option<PathBuf> {
    let mut result = PathBuf::new();
    for component in path.components() {
        match component {
            Component::Normal(c) => result.push(c),
            Component::CurDir => {} // Skip "."
            Component::ParentDir => return None, // Reject ".."
            Component::Prefix(_) | Component::RootDir => return None, // Reject absolute paths
        }
    }
    if result.as_os_str().is_empty() {
        None
    } else {
        Some(result)
    }
}

/// Optimized file copy with buffering for better performance
/// Uses a larger buffer (4MB) for faster I/O operations
fn copy_file_optimized<R: std::io::Read + ?Sized, W: std::io::Write>(
    reader: &mut R,
    writer: &mut W,
) -> std::io::Result<u64> {
    const BUFFER_SIZE: usize = 4 * 1024 * 1024; // 4MB buffer for better performance
    let mut buffer = vec![0u8; BUFFER_SIZE];
    let mut total_bytes = 0u64;

    loop {
        let bytes_read = reader.read(&mut buffer)?;
        if bytes_read == 0 {
            break;
        }
        writer.write_all(&buffer[..bytes_read])?;
        total_bytes += bytes_read as u64;
    }

    Ok(total_bytes)
}

/// Remove read-only attribute from a file (Windows only)
#[cfg(target_os = "windows")]
fn remove_readonly_attribute(path: &Path) -> Result<()> {
    let metadata = fs::metadata(path)?;
    let mut permissions = metadata.permissions();

    // Check if file is read-only
    if permissions.readonly() {
        permissions.set_readonly(false);
        fs::set_permissions(path, permissions)
            .context(format!("Failed to remove read-only attribute from: {:?}", path))?;
    }
    Ok(())
}

/// Remove read-only attribute from a file (non-Windows platforms)
#[cfg(not(target_os = "windows"))]
fn remove_readonly_attribute(_path: &Path) -> Result<()> {
    // On Unix-like systems, we handle permissions differently
    Ok(())
}

/// Robustly remove a directory and all its contents, handling read-only files
/// Includes retry logic with exponential backoff for Windows file locking issues
fn remove_dir_all_robust(path: &Path) -> Result<()> {
    if !path.exists() {
        return Ok(());
    }

    // First pass: remove read-only attributes from all files
    for entry in walkdir::WalkDir::new(path).follow_links(false) {
        if let Ok(entry) = entry {
            let entry_path = entry.path();
            if entry_path.is_file() {
                // Try to remove read-only attribute, but don't fail if it doesn't work
                let _ = remove_readonly_attribute(entry_path);
            }
        }
    }

    // Try to delete with retries (handles temporary file locks from antivirus, indexing, etc.)
    const MAX_RETRIES: u32 = 3;
    const INITIAL_DELAY_MS: u64 = 100;

    let mut last_error = None;
    for attempt in 0..=MAX_RETRIES {
        match fs::remove_dir_all(path) {
            Ok(()) => return Ok(()),
            Err(e) => {
                last_error = Some(e);
                if attempt < MAX_RETRIES {
                    // Exponential backoff: 100ms, 200ms, 400ms
                    let delay = INITIAL_DELAY_MS * (1 << attempt);
                    std::thread::sleep(std::time::Duration::from_millis(delay));
                }
            }
        }
    }

    // All retries failed, provide detailed error information
    let e = last_error.unwrap();
    let err_msg = format!(
        "Failed to delete directory: {:?}\nError: {}\n\
        This may be caused by:\n\
        - Files being used by another program (X-Plane, file explorer, antivirus)\n\
        - Insufficient permissions\n\
        - System files or protected folders\n\
        Please close any programs that might be using these files and try again.",
        path, e
    );
    Err(anyhow::anyhow!(err_msg))
}

/// Directory statistics for backup verification
struct DirectoryInfo {
    file_count: u64,
    total_size: u64,
}

/// Backup data for Aircraft overwrites
struct AircraftBackup {
    temp_dir: PathBuf,
    liveries_path: Option<PathBuf>,
    pref_files: Vec<(String, PathBuf)>, // (filename, temp_path)
    // For verification
    original_liveries_info: Option<DirectoryInfo>,
    original_pref_sizes: Vec<(String, u64)>, // (filename, original_size)
}

/// Progress tracking context
struct ProgressContext {
    app_handle: AppHandle,
    total_bytes: Arc<AtomicU64>,
    processed_bytes: Arc<AtomicU64>,
    last_emit: Arc<Mutex<Instant>>,
    current_task_index: usize,
    total_tasks: usize,
    current_task_name: String,
}

impl ProgressContext {
    fn new(app_handle: AppHandle, total_tasks: usize) -> Self {
        Self {
            app_handle,
            total_bytes: Arc::new(AtomicU64::new(0)),
            processed_bytes: Arc::new(AtomicU64::new(0)),
            last_emit: Arc::new(Mutex::new(Instant::now())),
            current_task_index: 0,
            total_tasks,
            current_task_name: String::new(),
        }
    }

    fn set_total_bytes(&self, total: u64) {
        self.total_bytes.store(total, Ordering::SeqCst);
    }

    fn add_bytes(&self, bytes: u64) {
        self.processed_bytes.fetch_add(bytes, Ordering::SeqCst);
    }

    fn emit_progress(&self, current_file: Option<String>, phase: InstallPhase) {
        // Throttle: emit at most every 16ms (60fps for smooth animation)
        let mut last = match self.last_emit.lock() {
            Ok(guard) => guard,
            Err(_) => return, // Skip progress update if lock is poisoned
        };
        let now = Instant::now();
        if now.duration_since(*last).as_millis() < 16 {
            return;
        }
        *last = now;
        drop(last);

        let total = self.total_bytes.load(Ordering::SeqCst);
        let processed = self.processed_bytes.load(Ordering::SeqCst);
        let percentage = if total > 0 {
            (processed as f64 / total as f64) * 100.0
        } else {
            0.0
        };

        let progress = InstallProgress {
            percentage,
            total_bytes: total,
            processed_bytes: processed,
            current_task_index: self.current_task_index,
            total_tasks: self.total_tasks,
            current_task_name: self.current_task_name.clone(),
            current_file,
            phase,
        };

        let _ = self.app_handle.emit("install-progress", &progress);
    }

    fn emit_final(&self, phase: InstallPhase) {
        let total = self.total_bytes.load(Ordering::SeqCst);
        let processed = self.processed_bytes.load(Ordering::SeqCst);
        let percentage = if total > 0 {
            (processed as f64 / total as f64) * 100.0
        } else {
            100.0
        };

        let progress = InstallProgress {
            percentage,
            total_bytes: total,
            processed_bytes: processed,
            current_task_index: self.current_task_index,
            total_tasks: self.total_tasks,
            current_task_name: self.current_task_name.clone(),
            current_file: None,
            phase,
        };

        let _ = self.app_handle.emit("install-progress", &progress);
    }
}

pub struct Installer {
    app_handle: AppHandle,
}

impl Installer {
    pub fn new(app_handle: AppHandle) -> Self {
        Installer { app_handle }
    }

    /// Install a list of tasks with progress reporting
    pub fn install(&self, tasks: Vec<InstallTask>) -> Result<InstallResult> {
        logger::log_info(
            &format!("{}: {} task(s)", tr(LogMsg::InstallationStarted), tasks.len()),
            Some("installer"),
        );

        let mut ctx = ProgressContext::new(self.app_handle.clone(), tasks.len());
        let mut task_results = Vec::new();
        let mut successful = 0;
        let mut failed = 0;

        // Phase 1: Calculate total size
        ctx.emit_progress(None, InstallPhase::Calculating);
        let total_size = self.calculate_total_size(&tasks)?;
        ctx.set_total_bytes(total_size);

        // Phase 2: Install each task
        for (index, task) in tasks.iter().enumerate() {
            ctx.current_task_index = index;
            ctx.current_task_name = task.display_name.clone();
            ctx.emit_progress(None, InstallPhase::Installing);

            logger::log_info(
                &format!("{}: {} -> {}", tr(LogMsg::Installing), task.display_name, task.target_path),
                Some("installer"),
            );

            match self.install_task_with_progress(task, &ctx) {
                Ok(_) => {
                    successful += 1;
                    task_results.push(TaskResult {
                        task_id: task.id.clone(),
                        task_name: task.display_name.clone(),
                        success: true,
                        error_message: None,
                    });
                }
                Err(e) => {
                    failed += 1;
                    let error_msg = format!("{}", e);
                    logger::log_error(
                        &format!("{} {}: {}", tr(LogMsg::InstallationFailed), task.display_name, error_msg),
                        Some("installer"),
                    );
                    task_results.push(TaskResult {
                        task_id: task.id.clone(),
                        task_name: task.display_name.clone(),
                        success: false,
                        error_message: Some(error_msg),
                    });
                }
            }
        }

        // Phase 3: Finalize
        ctx.emit_final(InstallPhase::Finalizing);
        logger::log_info(&tr(LogMsg::InstallationCompleted), Some("installer"));

        Ok(InstallResult {
            total_tasks: tasks.len(),
            successful_tasks: successful,
            failed_tasks: failed,
            task_results,
        })
    }

    /// Calculate total size of all tasks for progress tracking
    fn calculate_total_size(&self, tasks: &[InstallTask]) -> Result<u64> {
        let mut total = 0u64;
        for task in tasks {
            let source = Path::new(&task.source_path);
            if source.is_dir() {
                total += self.get_directory_size(source)?;
            } else if source.is_file() {
                total += self.get_archive_size(source, task.archive_internal_root.as_deref())?;
            }
        }
        Ok(total)
    }

    /// Get total size of files in a directory
    fn get_directory_size(&self, dir: &Path) -> Result<u64> {
        let mut size = 0u64;
        for entry in walkdir::WalkDir::new(dir).follow_links(false) {
            let entry = entry?;
            if entry.file_type().is_file() {
                size += entry.metadata()?.len();
            }
        }
        Ok(size)
    }

    /// Get uncompressed size of archive
    fn get_archive_size(&self, archive: &Path, internal_root: Option<&str>) -> Result<u64> {
        let ext = archive.extension().and_then(|s| s.to_str());
        match ext {
            Some("zip") => self.get_zip_size(archive, internal_root),
            Some("7z") => self.get_7z_size(archive),
            Some("rar") => self.get_rar_size(archive),
            _ => Ok(0),
        }
    }

    /// Get uncompressed size of ZIP archive
    fn get_zip_size(&self, archive: &Path, internal_root: Option<&str>) -> Result<u64> {
        use zip::ZipArchive;
        let file = fs::File::open(archive)?;
        let mut archive_reader = ZipArchive::new(file)?;
        let prefix = internal_root.map(|s| s.replace('\\', "/"));

        let mut total = 0u64;
        for i in 0..archive_reader.len() {
            if let Ok(file) = archive_reader.by_index_raw(i) {
                let name = file.name().replace('\\', "/");
                if let Some(ref p) = prefix {
                    if !name.starts_with(p) {
                        continue;
                    }
                }
                total += file.size();
            }
        }
        Ok(total)
    }

    /// Get uncompressed size of 7z archive (estimate from file size)
    fn get_7z_size(&self, archive: &Path) -> Result<u64> {
        // sevenz-rust2 doesn't have easy size query, use compressed size * 3 as estimate
        let meta = fs::metadata(archive)?;
        Ok(meta.len() * 3)
    }

    /// Get uncompressed size of RAR archive
    fn get_rar_size(&self, archive: &Path) -> Result<u64> {
        let arch = unrar::Archive::new(archive)
            .open_for_listing()
            .map_err(|e| anyhow::anyhow!("Failed to open RAR for size query: {:?}", e))?;

        let mut total = 0u64;
        for entry in arch {
            if let Ok(e) = entry {
                total += e.unpacked_size;
            }
        }
        Ok(total)
    }

    /// Install a single task with progress tracking
    fn install_task_with_progress(&self, task: &InstallTask, ctx: &ProgressContext) -> Result<()> {
        let source = Path::new(&task.source_path);
        let target = Path::new(&task.target_path);
        let password = task.password.as_deref();

        // Create parent directory if it doesn't exist
        if let Some(parent) = target.parent() {
            fs::create_dir_all(parent)
                .context(format!("Failed to create target directory: {:?}", parent))?;
        }

        // Check if this is a nested archive installation
        if let Some(ref chain) = task.extraction_chain {
            // Nested archive: use recursive extraction
            if !task.should_overwrite && target.exists() {
                // Clean install mode for nested archives
                self.handle_clean_install_with_extraction_chain(task, source, target, chain, ctx, password)?;
            } else {
                // Direct overwrite mode for nested archives
                self.install_content_with_extraction_chain(source, target, chain, ctx, password)?;
            }
        } else {
            // Regular installation (non-nested)
            if !task.should_overwrite && target.exists() {
                // Clean install mode: delete old folder first
                self.handle_clean_install_with_progress(task, source, target, ctx, password)?;
            } else {
                // Direct overwrite mode: just install/extract files directly
                self.install_content_with_progress(source, target, task.archive_internal_root.as_deref(), ctx, password)?;
            }
        }

        Ok(())
    }

    /// Install content with progress tracking
    fn install_content_with_progress(
        &self,
        source: &Path,
        target: &Path,
        internal_root: Option<&str>,
        ctx: &ProgressContext,
        password: Option<&str>,
    ) -> Result<()> {
        if source.is_dir() {
            self.copy_directory_with_progress(source, target, ctx)?;
        } else if source.is_file() {
            self.extract_archive_with_progress(source, target, internal_root, ctx, password)?;
        } else {
            return Err(anyhow::anyhow!("Source path is neither file nor directory"));
        }
        Ok(())
    }

    /// Install content with extraction chain (for nested archives)
    /// Optimized version: ZIP archives are extracted directly from memory when possible
    fn install_content_with_extraction_chain(
        &self,
        source: &Path,
        target: &Path,
        chain: &crate::models::ExtractionChain,
        ctx: &ProgressContext,
        outermost_password: Option<&str>,
    ) -> Result<()> {
        use tempfile::TempDir;

        // For single-layer chains, use the optimized path
        if chain.archives.len() == 1 {
            // Just extract with internal_root
            return self.extract_archive_with_progress(
                source,
                target,
                chain.final_internal_root.as_deref(),
                ctx,
                outermost_password,
            );
        }

        // For multi-layer chains, check if we can use the memory-optimized path
        let all_zip = chain.archives.iter().all(|a| a.format == "zip");

        if all_zip {
            // Optimized path: Extract nested ZIPs directly from memory
            self.install_nested_zip_from_memory(source, target, chain, ctx, outermost_password)
        } else {
            // Fallback path: Use temp directory for 7z/RAR
            self.install_nested_with_temp(source, target, chain, ctx, outermost_password)
        }
    }

    /// Optimized installation for nested ZIP archives (memory-only, no temp files)
    fn install_nested_zip_from_memory(
        &self,
        source: &Path,
        target: &Path,
        chain: &crate::models::ExtractionChain,
        ctx: &ProgressContext,
        outermost_password: Option<&str>,
    ) -> Result<()> {
        use zip::ZipArchive;
        use std::io::{Cursor, Read};

        crate::logger::log_info(
            &format!("Using optimized memory extraction for {} nested ZIP layers", chain.archives.len()),
            Some("installer"),
        );

        // Open the outermost archive
        let file = fs::File::open(source)?;
        let mut current_archive_data = Vec::new();
        file.take(u64::MAX).read_to_end(&mut current_archive_data)?;

        let mut current_password = outermost_password.map(|s| s.as_bytes().to_vec());

        // Navigate through all layers except the last one
        for (index, archive_info) in chain.archives.iter().enumerate() {
            let is_last = index == chain.archives.len() - 1;

            let cursor = Cursor::new(&current_archive_data);
            let mut archive = ZipArchive::new(cursor)?;

            if is_last {
                // Last layer: extract to final target
                // Need to recreate cursor with owned data for final extraction
                let cursor = Cursor::new(current_archive_data);
                let mut archive = ZipArchive::new(cursor)?;

                // Extract all files
                self.extract_zip_from_archive(
                    &mut archive,
                    target,
                    chain.final_internal_root.as_deref(),
                    ctx,
                    current_password.as_deref(),
                )?;
                break; // Done
            } else {
                // Intermediate layer: read nested archive into memory
                let nested_path = &archive_info.internal_path;
                let mut nested_data = Vec::new();

                // Search for the nested archive
                let mut found = false;
                for i in 0..archive.len() {
                    let mut file = if let Some(pwd) = current_password.as_deref() {
                        match archive.by_index_decrypt(i, pwd) {
                            Ok(f) => f,
                            Err(_) => continue,
                        }
                    } else {
                        archive.by_index(i)?
                    };

                    if file.name() == nested_path {
                        file.read_to_end(&mut nested_data)?;
                        found = true;
                        break;
                    }
                }

                if !found {
                    return Err(anyhow::anyhow!(
                        "Nested archive not found in ZIP: {}",
                        nested_path
                    ));
                }

                // Update for next iteration
                current_archive_data = nested_data;
                current_password = archive_info.password.as_ref().map(|s| s.as_bytes().to_vec());
            }
        }

        Ok(())
    }

    /// Extract files from an in-memory ZIP archive
    fn extract_zip_from_archive<R: std::io::Read + std::io::Seek>(
        &self,
        archive: &mut zip::ZipArchive<R>,
        target: &Path,
        internal_root: Option<&str>,
        ctx: &ProgressContext,
        password: Option<&[u8]>,
    ) -> Result<()> {
        use std::sync::Arc;

        let internal_root_normalized = internal_root.map(|s| s.replace('\\', "/"));
        let prefix = internal_root_normalized.as_deref();

        // Collect all file entries
        let entries: Vec<_> = (0..archive.len())
            .filter_map(|i| {
                let file = archive.by_index(i).ok()?;
                let path = file.enclosed_name()?.to_path_buf();
                let file_path_str = path.to_string_lossy().replace('\\', "/");

                // Check prefix filter
                let relative_path = if let Some(prefix) = prefix {
                    file_path_str.strip_prefix(prefix)
                        .and_then(|s| s.strip_prefix('/').or(Some(s)))
                        .map(|s| s.to_string())?
                } else {
                    file_path_str.clone()
                };

                Some((i, relative_path, file.is_dir(), file.encrypted()))
            })
            .collect();

        // Create directories first
        for (_, relative_path, is_dir, _) in &entries {
            if *is_dir {
                let dir_path = target.join(relative_path);
                fs::create_dir_all(&dir_path)?;
            }
        }

        // Extract files in parallel
        let target_arc = Arc::new(target.to_path_buf());
        let password_arc = Arc::new(password.map(|p| p.to_vec()));
        let archive_path = Arc::new(
            archive.by_index(0)
                .ok()
                .and_then(|f| Some(f.name().to_string()))
                .unwrap_or_default()
        );

        use rayon::prelude::*;

        // For encrypted archives, we need to reopen for each thread
        // For now, extract sequentially if encrypted
        if entries.iter().any(|(_, _, _, encrypted)| *encrypted) {
            // Sequential extraction for encrypted files
            for (i, relative_path, is_dir, is_encrypted) in entries {
                if is_dir {
                    continue;
                }

                let target_path = target.join(&relative_path);
                if let Some(parent) = target_path.parent() {
                    fs::create_dir_all(parent)?;
                }

                let mut file = if is_encrypted {
                    if let Some(pwd) = password {
                        archive.by_index_decrypt(i, pwd)
                            .map_err(|e| anyhow::anyhow!("Failed to decrypt file: {}", e))?
                    } else {
                        return Err(anyhow::anyhow!("Password required for encrypted file"));
                    }
                } else {
                    archive.by_index(i)?
                };

                let mut output = fs::File::create(&target_path)?;
                std::io::copy(&mut file, &mut output)?;

                // Set permissions on Unix
                #[cfg(unix)]
                if let Some(mode) = file.unix_mode() {
                    use std::os::unix::fs::PermissionsExt;
                    fs::set_permissions(&target_path, fs::Permissions::from_mode(mode))?;
                }
            }
        } else {
            // Parallel extraction for non-encrypted files
            // Note: This requires reopening the archive for each thread
            // For in-memory archives, this is not straightforward
            // So we fall back to sequential for now
            for (i, relative_path, is_dir, _) in entries {
                if is_dir {
                    continue;
                }

                let target_path = target.join(&relative_path);
                if let Some(parent) = target_path.parent() {
                    fs::create_dir_all(parent)?;
                }

                let mut file = archive.by_index(i)?;
                let mut output = fs::File::create(&target_path)?;
                std::io::copy(&mut file, &mut output)?;

                #[cfg(unix)]
                if let Some(mode) = file.unix_mode() {
                    use std::os::unix::fs::PermissionsExt;
                    fs::set_permissions(&target_path, fs::Permissions::from_mode(mode))?;
                }
            }
        }

        Ok(())
    }

    /// Fallback installation for nested archives with temp directory (for 7z/RAR)
    /// Optimized for mixed formats: uses memory for ZIP layers when possible
    fn install_nested_with_temp(
        &self,
        source: &Path,
        target: &Path,
        chain: &crate::models::ExtractionChain,
        ctx: &ProgressContext,
        outermost_password: Option<&str>,
    ) -> Result<()> {
        use tempfile::TempDir;

        crate::logger::log_info(
            &format!("Using temp directory extraction for {} nested layers (mixed format optimization enabled)", chain.archives.len()),
            Some("installer"),
        );

        // Create temp directory for intermediate extractions
        let temp_base = TempDir::new()
            .context("Failed to create temp directory for nested extraction")?;

        let mut current_source = source.to_path_buf();
        let mut current_password = outermost_password;

        // Extract each layer in the chain
        for (index, archive_info) in chain.archives.iter().enumerate() {
            let is_last = index == chain.archives.len() - 1;
            let current_format = &archive_info.format;

            // Determine extraction target
            let extract_target = if is_last {
                // Last layer: extract directly to final target
                target.to_path_buf()
            } else {
                // Intermediate layer: extract to temp
                temp_base.path().join(format!("layer_{}", index))
            };

            // Create target directory
            fs::create_dir_all(&extract_target)
                .context(format!("Failed to create extraction target: {:?}", extract_target))?;

            // Extract the current archive
            crate::logger::log_info(
                &format!("Extracting layer {} ({}): {} to {:?}", index, current_format, archive_info.internal_path, extract_target),
                Some("installer"),
            );

            self.extract_archive_with_progress(
                &current_source,
                &extract_target,
                if is_last { chain.final_internal_root.as_deref() } else { None },
                ctx,
                current_password,
            )?;

            // For non-last layers, find the nested archive in the extracted content
            if !is_last {
                let nested_archive_path = extract_target.join(&archive_info.internal_path);

                if !nested_archive_path.exists() {
                    return Err(anyhow::anyhow!(
                        "Nested archive not found after extraction: {} (expected at {:?})",
                        archive_info.internal_path,
                        nested_archive_path
                    ));
                }

                // OPTIMIZATION: If next layer is ZIP, try to load it into memory
                if let Some(next_archive) = chain.archives.get(index + 1) {
                    if next_archive.format == "zip" {
                        crate::logger::log_info(
                            &format!("Optimizing: Loading ZIP layer {} into memory", index + 1),
                            Some("installer"),
                        );

                        // Try to read the ZIP into memory for faster processing
                        match self.try_extract_zip_from_memory(
                            &nested_archive_path,
                            target,
                            &chain.archives[(index + 1)..],
                            chain.final_internal_root.as_deref(),
                            ctx,
                            next_archive.password.as_deref(),
                        ) {
                            Ok(()) => {
                                // Successfully extracted from memory, we're done
                                crate::logger::log_info(
                                    "Memory optimization successful for remaining ZIP layers",
                                    Some("installer"),
                                );
                                return Ok(());
                            }
                            Err(e) => {
                                // Fall back to normal extraction
                                crate::logger::log_info(
                                    &format!("Memory optimization failed, falling back to temp extraction: {}", e),
                                    Some("installer"),
                                );
                            }
                        }
                    }
                }

                // Update source for next iteration
                current_source = nested_archive_path;

                // Update password for next layer if specified
                if let Some(next_archive) = chain.archives.get(index + 1) {
                    if next_archive.password.is_some() {
                        current_password = next_archive.password.as_deref();
                    }
                }
            }
        }

        // Temp directory automatically cleaned up when TempDir drops
        Ok(())
    }

    /// Try to extract remaining ZIP layers from memory (optimization for mixed formats)
    fn try_extract_zip_from_memory(
        &self,
        zip_path: &Path,
        target: &Path,
        remaining_chain: &[crate::models::NestedArchiveInfo],
        final_internal_root: Option<&str>,
        ctx: &ProgressContext,
        password: Option<&str>,
    ) -> Result<()> {
        use zip::ZipArchive;
        use std::io::{Cursor, Read};

        // Read the ZIP file into memory
        let mut zip_data = Vec::new();
        let mut file = fs::File::open(zip_path)?;
        file.read_to_end(&mut zip_data)?;

        let mut current_archive_data = zip_data;
        let mut current_password = password.map(|s| s.as_bytes().to_vec());

        // Process remaining ZIP layers in memory
        for (index, archive_info) in remaining_chain.iter().enumerate() {
            let is_last = index == remaining_chain.len() - 1;

            // Verify this is a ZIP layer
            if archive_info.format != "zip" {
                return Err(anyhow::anyhow!("Non-ZIP layer encountered in memory optimization"));
            }

            let cursor = Cursor::new(&current_archive_data);
            let mut archive = ZipArchive::new(cursor)?;

            if is_last {
                // Last layer: extract to final target
                let cursor = Cursor::new(current_archive_data);
                let mut archive = ZipArchive::new(cursor)?;

                self.extract_zip_from_archive(
                    &mut archive,
                    target,
                    final_internal_root,
                    ctx,
                    current_password.as_deref(),
                )?;
                break;
            } else {
                // Intermediate layer: read nested ZIP into memory
                let nested_path = &archive_info.internal_path;
                let mut nested_data = Vec::new();

                let mut found = false;
                for i in 0..archive.len() {
                    let mut file = if let Some(pwd) = current_password.as_deref() {
                        match archive.by_index_decrypt(i, pwd) {
                            Ok(f) => f,
                            Err(_) => continue,
                        }
                    } else {
                        archive.by_index(i)?
                    };

                    if file.name() == nested_path {
                        file.read_to_end(&mut nested_data)?;
                        found = true;
                        break;
                    }
                }

                if !found {
                    return Err(anyhow::anyhow!(
                        "Nested ZIP not found in memory: {}",
                        nested_path
                    ));
                }

                current_archive_data = nested_data;
                current_password = archive_info.password.as_ref().map(|s| s.as_bytes().to_vec());
            }
        }

        Ok(())
    }

    /// Move all contents from source directory to target directory
    fn move_directory_contents(&self, source: &Path, target: &Path) -> Result<()> {
        for entry in fs::read_dir(source)
            .context(format!("Failed to read source directory: {:?}", source))?
        {
            let entry = entry?;
            let source_path = entry.path();
            let file_name = entry.file_name();
            let target_path = target.join(&file_name);

            if source_path.is_dir() {
                // Try to rename (move) the directory
                if let Err(_) = fs::rename(&source_path, &target_path) {
                    // Fallback: copy and delete
                    self.copy_directory_with_progress(
                        &source_path,
                        &target_path,
                        &ProgressContext::new(self.app_handle.clone(), 1),
                    )?;
                    remove_dir_all_robust(&source_path)
                        .context(format!("Failed to remove source directory: {:?}", source_path))?;
                }
            } else {
                // Try to rename (move) the file
                if let Err(_) = fs::rename(&source_path, &target_path) {
                    // Fallback: copy and delete
                    fs::copy(&source_path, &target_path)
                        .context(format!("Failed to copy file: {:?}", source_path))?;
                    fs::remove_file(&source_path)
                        .context(format!("Failed to remove source file: {:?}", source_path))?;
                }
            }
        }
        Ok(())
    }

    /// Handle clean install with extraction chain (for nested archives)
    fn handle_clean_install_with_extraction_chain(
        &self,
        task: &crate::models::InstallTask,
        source: &Path,
        target: &Path,
        chain: &crate::models::ExtractionChain,
        ctx: &ProgressContext,
        password: Option<&str>,
    ) -> Result<()> {
        match task.addon_type {
            crate::models::AddonType::Aircraft => {
                // For Aircraft: backup liveries and prefs, delete, install, restore
                // Note: For nested archives, we don't have archive_internal_root,
                // so we'll use the extraction chain's final_internal_root
                self.handle_aircraft_clean_install_with_extraction_chain(
                    source,
                    target,
                    chain,
                    ctx,
                    password,
                    task.backup_liveries,
                    task.backup_config_files,
                    &task.config_file_patterns,
                )?;
            }
            crate::models::AddonType::Navdata => {
                // For Navdata: DON'T delete Custom Data folder!
                // Just extract and overwrite individual files
                self.install_content_with_extraction_chain(source, target, chain, ctx, password)?;
            }
            _ => {
                // For other types: delete and reinstall
                if target.exists() {
                    remove_dir_all_robust(target)
                        .context(format!("Failed to delete existing folder: {:?}", target))?;
                }
                self.install_content_with_extraction_chain(source, target, chain, ctx, password)?;
            }
        }
        Ok(())
    }

    /// Handle aircraft clean install with extraction chain
    fn handle_aircraft_clean_install_with_extraction_chain(
        &self,
        source: &Path,
        target: &Path,
        chain: &crate::models::ExtractionChain,
        ctx: &ProgressContext,
        password: Option<&str>,
        backup_liveries: bool,
        backup_config_files: bool,
        config_file_patterns: &[String],
    ) -> Result<()> {
        use tempfile::Builder;
        use uuid::Uuid;

        // Step 1: Backup liveries and config files if requested
        let backup_dir = if (backup_liveries || backup_config_files) && target.exists() {
            let temp_dir = std::env::temp_dir();
            let backup_path = temp_dir.join(format!("xfastinstall_backup_{}", Uuid::new_v4()));
            fs::create_dir_all(&backup_path)
                .context("Failed to create backup directory")?;

            // Backup liveries
            if backup_liveries {
                let liveries_src = target.join("liveries");
                if liveries_src.exists() {
                    let liveries_dst = backup_path.join("liveries");
                    self.copy_directory_with_progress(&liveries_src, &liveries_dst, ctx)?;
                }
            }

            // Backup config files
            if backup_config_files {
                for pattern in config_file_patterns {
                    for entry in glob::glob(&target.join(pattern).to_string_lossy())
                        .context("Failed to read glob pattern")?
                    {
                        if let Ok(config_file) = entry {
                            if config_file.is_file() {
                                let file_name = config_file.file_name().unwrap();
                                let backup_file = backup_path.join(file_name);
                                fs::copy(&config_file, &backup_file)
                                    .context(format!("Failed to backup config file: {:?}", config_file))?;
                            }
                        }
                    }
                }
            }

            Some(backup_path)
        } else {
            None
        };

        // Step 2: Delete existing aircraft folder
        if target.exists() {
            remove_dir_all_robust(target)
                .context(format!("Failed to delete existing aircraft folder: {:?}", target))?;
        }

        // Step 3: Install new aircraft using extraction chain
        self.install_content_with_extraction_chain(source, target, chain, ctx, password)?;

        // Step 4: Restore backed up files
        if let Some(backup_path) = backup_dir {
            // Restore liveries
            let liveries_backup = backup_path.join("liveries");
            if liveries_backup.exists() {
                let liveries_target = target.join("liveries");
                self.copy_directory_with_progress(&liveries_backup, &liveries_target, ctx)?;
            }

            // Restore config files
            for entry in fs::read_dir(&backup_path)
                .context("Failed to read backup directory")?
            {
                let entry = entry?;
                let path = entry.path();
                if path.is_file() {
                    let file_name = path.file_name().unwrap();
                    let target_file = target.join(file_name);
                    fs::copy(&path, &target_file)
                        .context(format!("Failed to restore config file: {:?}", path))?;
                }
            }

            // Verify restoration and cleanup backup
            if target.exists() {
                fs::remove_dir_all(&backup_path)
                    .context("Failed to cleanup backup directory")?;
            }
        }

        Ok(())
    }

    /// Handle clean install with progress tracking
    /// Deletes old folder first, then installs fresh
    fn handle_clean_install_with_progress(
        &self,
        task: &InstallTask,
        source: &Path,
        target: &Path,
        ctx: &ProgressContext,
        password: Option<&str>,
    ) -> Result<()> {
        match task.addon_type {
            AddonType::Aircraft => {
                // For Aircraft: backup liveries and prefs, delete, install, restore
                self.handle_aircraft_clean_install_with_progress(
                    source,
                    target,
                    task.archive_internal_root.as_deref(),
                    ctx,
                    password,
                    task.backup_liveries,
                    task.backup_config_files,
                    &task.config_file_patterns,
                )?;
            }
            AddonType::Navdata => {
                // For Navdata: DON'T delete Custom Data folder!
                // Just extract and overwrite individual files (same as direct overwrite)
                self.install_content_with_progress(source, target, task.archive_internal_root.as_deref(), ctx, password)?;
            }
            _ => {
                // For other types: delete and reinstall using robust removal
                if target.exists() {
                    remove_dir_all_robust(target)
                        .context(format!("Failed to delete existing folder: {:?}", target))?;
                }
                self.install_content_with_progress(source, target, task.archive_internal_root.as_deref(), ctx, password)?;
            }
        }
        Ok(())
    }

    /// Aircraft clean install with progress tracking
    fn handle_aircraft_clean_install_with_progress(
        &self,
        source: &Path,
        target: &Path,
        internal_root: Option<&str>,
        ctx: &ProgressContext,
        password: Option<&str>,
        backup_liveries: bool,
        backup_config_files: bool,
        config_patterns: &[String],
    ) -> Result<()> {
        // Step 1: Create backup of important files
        let backup = self.backup_aircraft_data(target, backup_liveries, backup_config_files, config_patterns, ctx)?;

        // Step 2: VERIFY backup is complete and valid BEFORE deleting
        if let Some(ref backup_data) = backup {
            self.verify_backup(backup_data)
                .context("Backup verification failed - aborting to protect your data")?;
        }

        // Step 3: Delete target folder (only after backup is verified)
        if target.exists() {
            remove_dir_all_robust(target)
                .context(format!("Failed to delete existing aircraft folder: {:?}", target))?;
        }

        // Step 4: Install new content with progress
        let install_result = self.install_content_with_progress(source, target, internal_root, ctx, password);

        // Step 5: Restore backup and verify
        let restore_verified = if let Some(ref backup_data) = backup {
            match self.restore_aircraft_backup(backup_data, target, ctx) {
                Ok(()) => {
                    match self.verify_restore(backup_data, target) {
                        Ok(()) => true,
                        Err(e) => {
                            return Err(anyhow::anyhow!(
                                "Restore verification failed: {}. Your backup is preserved at: {:?}.",
                                e, backup_data.temp_dir
                            ));
                        }
                    }
                }
                Err(e) => {
                    return Err(anyhow::anyhow!(
                        "Failed to restore backup: {}. Your backup is preserved at: {:?}.",
                        e, backup_data.temp_dir
                    ));
                }
            }
        } else {
            true
        };

        // Step 6: Cleanup temp backup directory ONLY if restore was verified
        if restore_verified {
            if let Some(backup_data) = backup {
                let _ = fs::remove_dir_all(&backup_data.temp_dir);
            }
        }

        install_result?;
        Ok(())
    }

    /// Backup aircraft liveries folder and config files
    fn backup_aircraft_data(
        &self,
        target: &Path,
        backup_liveries: bool,
        backup_config_files: bool,
        config_patterns: &[String],
        ctx: &ProgressContext,
    ) -> Result<Option<AircraftBackup>> {
        if !target.exists() {
            return Ok(None);
        }

        // Update progress: Starting backup
        ctx.emit_progress(Some("Backing up aircraft data...".to_string()), InstallPhase::Installing);

        // Create temp directory for backup
        let temp_dir = std::env::temp_dir().join(format!("xfastinstall_backup_{}", uuid::Uuid::new_v4()));
        fs::create_dir_all(&temp_dir)
            .context("Failed to create backup directory - check disk space")?;

        let mut backup = AircraftBackup {
            temp_dir: temp_dir.clone(),
            liveries_path: None,
            pref_files: Vec::new(),
            original_liveries_info: None,
            original_pref_sizes: Vec::new(),
        };

        // Backup liveries folder (root level only) if enabled
        if backup_liveries {
            let liveries_src = target.join("liveries");
            if liveries_src.exists() && liveries_src.is_dir() {
                ctx.emit_progress(Some("Backing up liveries...".to_string()), InstallPhase::Installing);

                // Record original info for verification
                let original_info = self.get_directory_info(&liveries_src)?;
                backup.original_liveries_info = Some(original_info);

                let liveries_dst = temp_dir.join("liveries");
                self.copy_directory_with_progress(&liveries_src, &liveries_dst, ctx)
                    .context("Failed to backup liveries folder")?;
                backup.liveries_path = Some(liveries_dst);
            }
        }

        // Backup config files from root directory only if enabled
        if backup_config_files && !config_patterns.is_empty() {
            ctx.emit_progress(Some("Backing up config files...".to_string()), InstallPhase::Installing);

            for entry in fs::read_dir(target)? {
                let entry = entry?;
                let path = entry.path();

                if path.is_file() {
                    if let Some(name) = path.file_name().and_then(|s| s.to_str()) {
                        if matches_any_pattern(name, config_patterns) {
                            let original_size = fs::metadata(&path)?.len();
                            let backup_path = temp_dir.join(name);
                            fs::copy(&path, &backup_path)
                                .context(format!("Failed to backup {}", name))?;
                            backup.pref_files.push((name.to_string(), backup_path.clone()));
                            backup.original_pref_sizes.push((name.to_string(), original_size));

                            // Update progress for each config file
                            ctx.add_bytes(original_size);
                        }
                    }
                }
            }
        }

        Ok(Some(backup))
    }

    /// Get directory info (file count and total size) for verification
    fn get_directory_info(&self, dir: &Path) -> Result<DirectoryInfo> {
        let mut file_count = 0u64;
        let mut total_size = 0u64;

        for entry in walkdir::WalkDir::new(dir).follow_links(false) {
            let entry = entry?;
            if entry.file_type().is_file() {
                file_count += 1;
                total_size += entry.metadata()?.len();
            }
        }

        Ok(DirectoryInfo { file_count, total_size })
    }

    /// Verify backup is complete and valid before proceeding with deletion
    fn verify_backup(&self, backup: &AircraftBackup) -> Result<()> {
        // Verify liveries backup
        if let (Some(ref liveries_backup_path), Some(ref original_info)) =
            (&backup.liveries_path, &backup.original_liveries_info)
        {
            if !liveries_backup_path.exists() {
                anyhow::bail!("Liveries backup folder does not exist");
            }

            let backup_info = self.get_directory_info(liveries_backup_path)?;

            if backup_info.file_count != original_info.file_count {
                anyhow::bail!(
                    "Liveries backup incomplete: expected {} files, got {}",
                    original_info.file_count,
                    backup_info.file_count
                );
            }

            if backup_info.total_size != original_info.total_size {
                anyhow::bail!(
                    "Liveries backup size mismatch: expected {} bytes, got {}",
                    original_info.total_size,
                    backup_info.total_size
                );
            }
        }

        // Verify pref files backup
        for (filename, original_size) in &backup.original_pref_sizes {
            let backup_path = backup.temp_dir.join(filename);

            if !backup_path.exists() {
                anyhow::bail!("Backup of {} does not exist", filename);
            }

            let backup_size = fs::metadata(&backup_path)?.len();
            if backup_size != *original_size {
                anyhow::bail!(
                    "Backup of {} has wrong size: expected {} bytes, got {}",
                    filename,
                    original_size,
                    backup_size
                );
            }
        }

        Ok(())
    }

    /// Verify restore was successful by checking restored files exist and have correct sizes
    fn verify_restore(&self, backup: &AircraftBackup, target: &Path) -> Result<()> {
        // Verify pref files were restored (these should always be overwritten)
        for (filename, original_size) in &backup.original_pref_sizes {
            let restored_path = target.join(filename);

            if !restored_path.exists() {
                anyhow::bail!("Restored file {} does not exist", filename);
            }

            let restored_size = fs::metadata(&restored_path)?.len();
            if restored_size != *original_size {
                anyhow::bail!(
                    "Restored file {} has wrong size: expected {} bytes, got {}",
                    filename,
                    original_size,
                    restored_size
                );
            }
        }

        // For liveries, we only verify files that should have been restored
        // (files that don't exist in the new addon were copied from backup)
        // This is harder to verify precisely, so we just check the folder exists if we had a backup
        if backup.liveries_path.is_some() {
            let liveries_target = target.join("liveries");
            if !liveries_target.exists() {
                anyhow::bail!("Liveries folder was not restored");
            }
        }

        Ok(())
    }

    /// Restore aircraft backup data
    fn restore_aircraft_backup(&self, backup: &AircraftBackup, target: &Path, ctx: &ProgressContext) -> Result<()> {
        ctx.emit_progress(Some("Restoring backup...".to_string()), InstallPhase::Installing);

        // Restore liveries folder (skip existing - don't overwrite new content)
        if let Some(ref liveries_backup) = backup.liveries_path {
            ctx.emit_progress(Some("Restoring liveries...".to_string()), InstallPhase::Installing);

            let liveries_target = target.join("liveries");

            if liveries_target.exists() {
                // Merge: copy only files that don't exist in new content
                self.merge_directory_skip_existing_with_progress(liveries_backup, &liveries_target, ctx)?;
            } else {
                // No new liveries folder, restore entire backup
                self.copy_directory_with_progress(liveries_backup, &liveries_target, ctx)?;
            }
        }

        // Restore *_prefs.txt files (always overwrite - restore user preferences)
        if !backup.pref_files.is_empty() {
            ctx.emit_progress(Some("Restoring config files...".to_string()), InstallPhase::Installing);

            for (filename, backup_path) in &backup.pref_files {
                let target_path = target.join(filename);
                let size = fs::metadata(backup_path)?.len();
                fs::copy(backup_path, &target_path)
                    .context(format!("Failed to restore pref file: {}", filename))?;

                // Update progress for each config file
                ctx.add_bytes(size);
            }
        }

        Ok(())
    }

    /// Copy directory contents, skipping files that already exist in target (with progress)
    fn merge_directory_skip_existing_with_progress(&self, source: &Path, target: &Path, ctx: &ProgressContext) -> Result<()> {
        if !target.exists() {
            fs::create_dir_all(target)?;
        }

        for entry in fs::read_dir(source)? {
            let entry = entry?;
            let file_type = entry.file_type()?;
            let source_path = entry.path();
            let file_name = entry.file_name();
            let target_path = target.join(&file_name);

            if file_type.is_dir() {
                // Recursively merge subdirectories
                self.merge_directory_skip_existing_with_progress(&source_path, &target_path, ctx)?;
            } else {
                // Only copy if target doesn't exist (skip existing)
                if !target_path.exists() {
                    let size = fs::metadata(&source_path)?.len();
                    fs::copy(&source_path, &target_path)?;
                    // Remove read-only attribute from copied file
                    let _ = remove_readonly_attribute(&target_path);

                    // Update progress
                    ctx.add_bytes(size);
                }
            }
        }

        Ok(())
    }

    /// Copy a directory recursively with progress tracking
    /// Uses parallel processing for better performance on multi-core systems
    fn copy_directory_with_progress(
        &self,
        source: &Path,
        target: &Path,
        ctx: &ProgressContext,
    ) -> Result<()> {
        if !target.exists() {
            fs::create_dir_all(target)?;
        }

        // Collect all entries first
        let entries: Vec<_> = walkdir::WalkDir::new(source)
            .follow_links(false)
            .into_iter()
            .filter_map(|e| e.ok())
            .collect();

        // Create all directories first (must be sequential)
        for entry in &entries {
            if entry.file_type().is_dir() {
                let relative = entry.path().strip_prefix(source)
                    .context("Failed to strip prefix")?;
                let target_path = target.join(relative);
                fs::create_dir_all(&target_path)?;
            }
        }

        // Copy files in parallel using rayon
        use rayon::prelude::*;

        entries.par_iter()
            .filter(|entry| entry.file_type().is_file())
            .try_for_each(|entry| -> Result<()> {
                let source_path = entry.path();
                let relative = source_path.strip_prefix(source)?;
                let target_path = target.join(relative);

                let file_size = entry.metadata()?.len();
                let file_name = source_path
                    .file_name()
                    .and_then(|s| s.to_str())
                    .unwrap_or("unknown")
                    .to_string();

                // Use optimized buffered copy
                let mut source_file = fs::File::open(source_path)
                    .context(format!("Failed to open source file {:?}", source_path))?;
                let mut target_file = fs::File::create(&target_path)
                    .context(format!("Failed to create target file {:?}", target_path))?;
                copy_file_optimized(&mut source_file, &mut target_file)?;

                // Remove read-only attribute from copied file to avoid future deletion issues
                let _ = remove_readonly_attribute(&target_path);

                ctx.add_bytes(file_size);
                ctx.emit_progress(Some(file_name), InstallPhase::Installing);

                Ok(())
            })?;

        Ok(())
    }

    /// Extract an archive with progress tracking
    fn extract_archive_with_progress(
        &self,
        archive: &Path,
        target: &Path,
        internal_root: Option<&str>,
        ctx: &ProgressContext,
        password: Option<&str>,
    ) -> Result<()> {
        let extension = archive
            .extension()
            .and_then(|s| s.to_str())
            .ok_or_else(|| anyhow::anyhow!("No file extension"))?;

        match extension {
            "zip" => self.extract_zip_with_progress(archive, target, internal_root, ctx, password)?,
            "7z" => self.extract_7z_with_progress(archive, target, internal_root, ctx, password)?,
            "rar" => self.extract_rar_with_progress(archive, target, internal_root, ctx, password)?,
            _ => return Err(anyhow::anyhow!("Unsupported archive format: {}", extension)),
        }

        Ok(())
    }

    /// Extract ZIP archive with progress tracking
    /// Supports password-protected ZIP files (both ZipCrypto and AES encryption)
    /// Uses parallel extraction for better performance on multi-core systems
    fn extract_zip_with_progress(
        &self,
        archive_path: &Path,
        target: &Path,
        internal_root: Option<&str>,
        ctx: &ProgressContext,
        password: Option<&str>,
    ) -> Result<()> {
        use zip::ZipArchive;
        use std::sync::Arc;

        // Open archive and collect file metadata
        let file = fs::File::open(archive_path)?;
        let mut archive = ZipArchive::new(file)?;

        let internal_root_normalized = internal_root.map(|s| s.replace('\\', "/"));
        let prefix = internal_root_normalized.as_deref();
        let password_bytes = password.map(|p| p.as_bytes().to_vec());

        // Collect all file entries with their metadata
        let entries: Vec<_> = (0..archive.len())
            .filter_map(|i| {
                let file = archive.by_index(i).ok()?;
                let path = file.enclosed_name()?.to_path_buf();
                let file_path_str = path.to_string_lossy().replace('\\', "/");

                // Check prefix filter
                let relative_path = if let Some(prefix) = prefix {
                    if !file_path_str.starts_with(prefix) {
                        return None;
                    }
                    let stripped = file_path_str
                        .strip_prefix(prefix)
                        .unwrap_or(&file_path_str)
                        .trim_start_matches('/');
                    if stripped.is_empty() {
                        return None;
                    }
                    sanitize_path(Path::new(stripped))?
                } else {
                    sanitize_path(&path)?
                };

                Some((i, relative_path, file.is_dir(), file.encrypted(), file.size()))
            })
            .collect();

        drop(archive); // Close the archive before parallel processing

        // Create all directories first (sequential)
        let file = fs::File::open(archive_path)?;
        let archive = ZipArchive::new(file)?;

        for (_index, relative_path, is_dir, _, _) in &entries {
            if *is_dir {
                let outpath = target.join(relative_path);
                fs::create_dir_all(&outpath)?;
            }
        }

        drop(archive);

        // Extract files in parallel
        use rayon::prelude::*;

        let archive_path = archive_path.to_path_buf();
        let target = target.to_path_buf();
        let password_bytes = Arc::new(password_bytes);

        entries.par_iter()
            .filter(|(_, _, is_dir, _, _)| !is_dir)
            .try_for_each(|(index, relative_path, _, is_encrypted, _)| -> Result<()> {
                // Each thread opens its own ZipArchive instance
                let file = fs::File::open(&archive_path)?;
                let mut archive = ZipArchive::new(file)?;

                let outpath = target.join(relative_path);

                if let Some(p) = outpath.parent() {
                    if !p.exists() {
                        fs::create_dir_all(p)?;
                    }
                }

                // Extract file with or without password
                let file_size = if *is_encrypted {
                    if let Some(ref pwd) = password_bytes.as_ref() {
                        match archive.by_index_decrypt(*index, pwd) {
                            Ok(mut file) => {
                                let size = file.size();
                                let mut outfile = fs::File::create(&outpath)?;
                                copy_file_optimized(&mut file, &mut outfile)?;
                                size
                            }
                            Err(e) => {
                                return Err(e.into());
                            }
                        }
                    } else {
                        return Err(anyhow::anyhow!(
                            "Password required for encrypted file: {}",
                            relative_path.display()
                        ));
                    }
                } else {
                    let mut file = archive.by_index(*index)?;
                    let size = file.size();
                    let mut outfile = fs::File::create(&outpath)?;
                    copy_file_optimized(&mut file, &mut outfile)?;
                    size
                };

                let file_name = relative_path
                    .file_name()
                    .and_then(|s| s.to_str())
                    .unwrap_or("unknown")
                    .to_string();

                ctx.add_bytes(file_size);
                ctx.emit_progress(Some(file_name), InstallPhase::Installing);

                #[cfg(unix)]
                {
                    use std::os::unix::fs::PermissionsExt;
                    let file = archive.by_index(*index)?;
                    if let Some(mode) = file.unix_mode() {
                        fs::set_permissions(&outpath, fs::Permissions::from_mode(mode))?;
                    }
                }

                Ok(())
            })?;

        Ok(())
    }

    /// Extract 7z archive with progress tracking
    /// Since sevenz-rust2 doesn't provide per-file callbacks, we extract to temp then copy with progress
    fn extract_7z_with_progress(
        &self,
        archive: &Path,
        target: &Path,
        internal_root: Option<&str>,
        ctx: &ProgressContext,
        password: Option<&str>,
    ) -> Result<()> {
        // Create secure temp directory using tempfile crate
        let temp_dir = tempfile::Builder::new()
            .prefix("xfastinstall_7z_")
            .tempdir()
            .context("Failed to create secure temp directory")?;

        // Extract with password if provided
        if let Some(pwd) = password {
            let mut reader = sevenz_rust2::SevenZReader::open(archive, sevenz_rust2::Password::from(pwd))
                .map_err(|e| anyhow::anyhow!("Failed to open 7z with password: {}", e))?;
            reader.for_each_entries(|entry, reader| {
                let dest_path = temp_dir.path().join(entry.name());
                if entry.is_directory() {
                    std::fs::create_dir_all(&dest_path)?;
                } else {
                    if let Some(parent) = dest_path.parent() {
                        std::fs::create_dir_all(parent)?;
                    }
                    let mut file = std::fs::File::create(&dest_path)?;
                    copy_file_optimized(reader, &mut file)?;
                }
                Ok(true)
            }).map_err(|e| anyhow::anyhow!("Failed to extract 7z with password: {}", e))?;
        } else {
            sevenz_rust2::decompress_file(archive, temp_dir.path())
                .map_err(|e| anyhow::anyhow!("Failed to extract 7z: {}", e))?;
        }

        // Determine source path (with or without internal_root)
        let source_path = if let Some(internal_root) = internal_root {
            let internal_root_normalized = internal_root.replace('\\', "/");
            let path = temp_dir.path().join(&internal_root_normalized);
            if path.exists() && path.is_dir() {
                path
            } else {
                temp_dir.path().to_path_buf()
            }
        } else {
            temp_dir.path().to_path_buf()
        };

        // Copy with progress tracking
        self.copy_directory_with_progress(&source_path, target, ctx)?;

        // TempDir automatically cleans up when dropped
        Ok(())
    }

    /// Extract RAR archive with progress tracking
    /// Similar to 7z - extract to temp then copy with progress
    fn extract_rar_with_progress(
        &self,
        archive: &Path,
        target: &Path,
        internal_root: Option<&str>,
        ctx: &ProgressContext,
        password: Option<&str>,
    ) -> Result<()> {
        // Create secure temp directory using tempfile crate
        let temp_dir = tempfile::Builder::new()
            .prefix("xfastinstall_rar_")
            .tempdir()
            .context("Failed to create secure temp directory")?;

        // Extract using the typestate pattern (with password if provided)
        let archive_builder = if let Some(pwd) = password {
            unrar::Archive::with_password(archive, pwd)
        } else {
            unrar::Archive::new(archive)
        };

        let mut arch = archive_builder
            .open_for_processing()
            .map_err(|e| anyhow::anyhow!("Failed to open RAR for extraction: {:?}", e))?;

        while let Some(header) = arch.read_header()
            .map_err(|e| anyhow::anyhow!("Failed to read RAR header: {:?}", e))?
        {
            arch = if header.entry().is_file() {
                header.extract_with_base(temp_dir.path())
                    .map_err(|e| anyhow::anyhow!("Failed to extract RAR entry: {:?}", e))?
            } else {
                header.skip()
                    .map_err(|e| anyhow::anyhow!("Failed to skip RAR entry: {:?}", e))?
            };
        }

        // Determine source path (with or without internal_root)
        let source_path = if let Some(internal_root) = internal_root {
            let internal_root_normalized = internal_root.replace('\\', "/");
            let path = temp_dir.path().join(&internal_root_normalized);
            if path.exists() && path.is_dir() {
                path
            } else {
                temp_dir.path().to_path_buf()
            }
        } else {
            temp_dir.path().to_path_buf()
        };

        // Copy with progress tracking
        self.copy_directory_with_progress(&source_path, target, ctx)?;

        // TempDir automatically cleans up when dropped
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sanitize_path_normal() {
        let path = Path::new("folder/subfolder/file.txt");
        let result = sanitize_path(path);
        assert!(result.is_some());
        assert_eq!(result.unwrap(), PathBuf::from("folder/subfolder/file.txt"));
    }

    #[test]
    fn test_sanitize_path_rejects_parent_dir() {
        let path = Path::new("folder/../../../etc/passwd");
        let result = sanitize_path(path);
        assert!(result.is_none(), "Path with .. should be rejected");
    }

    #[test]
    fn test_sanitize_path_rejects_absolute_unix() {
        let path = Path::new("/etc/passwd");
        let result = sanitize_path(path);
        assert!(result.is_none(), "Absolute Unix path should be rejected");
    }

    #[cfg(windows)]
    #[test]
    fn test_sanitize_path_rejects_absolute_windows() {
        let path = Path::new("C:\\Windows\\System32");
        let result = sanitize_path(path);
        assert!(result.is_none(), "Absolute Windows path should be rejected");
    }

    #[test]
    fn test_sanitize_path_handles_current_dir() {
        let path = Path::new("./folder/./file.txt");
        let result = sanitize_path(path);
        assert!(result.is_some());
        // Current dir markers should be skipped
        assert_eq!(result.unwrap(), PathBuf::from("folder/file.txt"));
    }

    #[test]
    fn test_sanitize_path_empty() {
        let path = Path::new("");
        let result = sanitize_path(path);
        assert!(result.is_none(), "Empty path should be rejected");
    }

    #[test]
    fn test_sanitize_path_only_parent() {
        let path = Path::new("..");
        let result = sanitize_path(path);
        assert!(result.is_none(), "Only parent dir should be rejected");
    }

    #[test]
    fn test_zip_bomb_constants() {
        // Verify constants are reasonable
        assert_eq!(MAX_EXTRACTION_SIZE, 20 * 1024 * 1024 * 1024); // 20 GB
        assert_eq!(MAX_COMPRESSION_RATIO, 100); // 100:1
    }
}
